{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# script to parse html-data from ziengs.nl and insert into sqlite ziengs.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr: 0\n",
      "pdp_pages: 0\n",
      "p_listings: 1\n",
      "other: 0\n",
      "nr: 100\n",
      "pdp_pages: 78\n",
      "p_listings: 23\n",
      "other: 0\n",
      "nr: 200\n",
      "pdp_pages: 171\n",
      "p_listings: 30\n",
      "other: 0\n",
      "nr: 300\n",
      "pdp_pages: 266\n",
      "p_listings: 35\n",
      "other: 0\n",
      "nr: 400\n",
      "pdp_pages: 362\n",
      "p_listings: 39\n",
      "other: 0\n",
      "nr: 500\n",
      "pdp_pages: 458\n",
      "p_listings: 43\n",
      "other: 0\n",
      "nr: 600\n",
      "pdp_pages: 555\n",
      "p_listings: 46\n",
      "other: 0\n",
      "nr: 700\n",
      "pdp_pages: 649\n",
      "p_listings: 52\n",
      "other: 0\n",
      "nr: 800\n",
      "pdp_pages: 745\n",
      "p_listings: 56\n",
      "other: 0\n",
      "nr: 900\n",
      "pdp_pages: 839\n",
      "p_listings: 62\n",
      "other: 0\n",
      "nr: 1000\n",
      "pdp_pages: 935\n",
      "p_listings: 66\n",
      "other: 0\n",
      "nr: 1100\n",
      "pdp_pages: 1032\n",
      "p_listings: 69\n",
      "other: 0\n",
      "nr: 1200\n",
      "pdp_pages: 1128\n",
      "p_listings: 73\n",
      "other: 0\n",
      "nr: 1300\n",
      "pdp_pages: 1225\n",
      "p_listings: 76\n",
      "other: 0\n",
      "nr: 1400\n",
      "pdp_pages: 1318\n",
      "p_listings: 83\n",
      "other: 0\n",
      "nr: 1500\n",
      "pdp_pages: 1407\n",
      "p_listings: 94\n",
      "other: 0\n",
      "nr: 1600\n",
      "pdp_pages: 1493\n",
      "p_listings: 108\n",
      "other: 0\n",
      "nr: 1700\n",
      "pdp_pages: 1590\n",
      "p_listings: 111\n",
      "other: 0\n",
      "nr: 1800\n",
      "pdp_pages: 1682\n",
      "p_listings: 119\n",
      "other: 0\n",
      "nr: 1900\n",
      "pdp_pages: 1772\n",
      "p_listings: 129\n",
      "other: 0\n",
      "nr: 2000\n",
      "pdp_pages: 1858\n",
      "p_listings: 143\n",
      "other: 0\n",
      "nr: 2100\n",
      "pdp_pages: 1949\n",
      "p_listings: 152\n",
      "other: 0\n",
      "nr: 2200\n",
      "pdp_pages: 2039\n",
      "p_listings: 162\n",
      "other: 0\n",
      "nr: 2300\n",
      "pdp_pages: 2122\n",
      "p_listings: 179\n",
      "other: 0\n",
      "nr: 2400\n",
      "pdp_pages: 2217\n",
      "p_listings: 184\n",
      "other: 0\n",
      "nr: 2500\n",
      "pdp_pages: 2310\n",
      "p_listings: 191\n",
      "other: 0\n",
      "nr: 2600\n",
      "pdp_pages: 2404\n",
      "p_listings: 197\n",
      "other: 0\n",
      "pdp_pages: 2458\n",
      "p_listings: 203\n",
      "other: 0\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect('ziengs.db')\n",
    "\n",
    "with con:\n",
    "    \n",
    "    cur = con.cursor()    \n",
    "                 \n",
    "    with open('crawl_ziengs.nl_2016-05-30T23-15-20.jl') as file:\n",
    "        \n",
    "        product_pages = []\n",
    "        product_listings = []\n",
    "        \n",
    "        for nr, line in enumerate(file):\n",
    "\n",
    "            data = json.loads(line)\n",
    "            soup = BeautifulSoup(data['body'],\"lxml\")\n",
    "\n",
    "            #two different page_types to parse: this is product_detail page. This data goes to separate tables in ziengs.db\n",
    "            if data['page_type'] == 'product_detail':           \n",
    "\n",
    "                product_id = soup.find(\"input\",{\"id\":\"hdnProductId\"}).get(\"value\")\n",
    "                title = soup.find(\"h1\", {\"itemprop\":\"name\"}).contents[0]\n",
    "                category = soup.find(\"meta\",{\"itemprop\":\"category\"}).get(\"content\")\n",
    "                brand = soup.find(\"meta\", {\"itemprop\":\"brand\"}).get(\"content\")\n",
    "                price = soup.find(\"meta\", {\"itemprop\":\"price\"}).get(\"content\")\n",
    "                page_url = data['page_url']\n",
    "                href_re = re.match(r'http://www.ziengs.nl/(.*)',page_url).group(1)\n",
    "                image = soup.find(\"meta\", {\"property\":\"og:image\"}).get(\"content\")\n",
    "                page_type = data['page_type']\n",
    "                crawled_at = data['crawled_at']\n",
    "                try: \n",
    "                    details = soup.find(\"div\", {\"class\":\"usp\"}).contents[0]\n",
    "                    if not isinstance(details,str): \n",
    "                         details = details[0]\n",
    "                except: details = ' '\n",
    "\n",
    "                product_pages.append((product_id,title,category,brand,price,page_url,href_re,image,page_type,crawled_at,details))\n",
    "\n",
    "            #two different page_types to parse: this is product_listing page. This data goes to separate tables in ziengs.db    \n",
    "            if data['page_type'] == 'product_listing':        \n",
    "\n",
    "                nr_products = soup.find(\"div\",{\"class\":\"productCount\"}).find(\"span\").contents[0].strip()\n",
    "\n",
    "                items = soup.findAll(\"div\",{\"class\":[\"item\",\"item last\",\"item vanvoor\",\"item vanvoor last\"]})\n",
    "                \n",
    "                crawled_at = data['crawled_at']\n",
    "                product_category = \", \".join(data['product_category'])\n",
    "                ordering = data['ordering']\n",
    "                page_number = data['page_number']\n",
    "                page_type = data['page_type']\n",
    "                page_url = data['page_url']\n",
    "                \n",
    "                position = 0 + (int(page_number)-1) * 24\n",
    "                for p_nr, item in enumerate(items):\n",
    "                    product_id = item.get(\"rel\")\n",
    "                    color_id = item.get(\"rev\")\n",
    "                    if product_id is not None:\n",
    "                        href = item.find(\"ul\",{\"data-colorid\":color_id})\n",
    "                        href2 = href.find(\"a\").get(\"href\")\n",
    "                        try: \n",
    "                            href_re = re.match(r'.*/([A-Za-z0-9].*)',href2).group(1)\n",
    "                        except: #code om te testen\n",
    "                            print item.prettify()\n",
    "                            print nr, p_nr, href, product_id\n",
    "                            print page_url\n",
    "                            print href2\n",
    "                            assert False\n",
    "                            \n",
    "                        position += 1\n",
    "                        product_listings.append((page_url, nr_products, page_number, position, ordering, product_id, href_re, product_category, page_type, crawled_at))\n",
    "                        \n",
    "        cur.executemany('insert into product_pages4 values (?,?,?,?,?,?,?,?,?,?,?)', product_pages)\n",
    "        cur.executemany('insert into product_listings4 values (?,?,?,?,?,?,?,?,?,?)', product_listings)\n",
    "        con.commit()\n",
    "\n",
    "        file.close()\n",
    "    \n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
